Figure 3.1 System Structure
 A  system is developed to identify raags based on pitch-class  distributions (PCDs) and pitch-class dyad distributions  (PCDDs) calculated directly from the audio signal [9].   Here, a large, assorted database consisting of 20 hours of  recorded performances in 31 different raags by 19  different performers was assembled to train and test the  system.  Classification was performed using support  vector machines, maximum a posteriori (MAP) rule using  a multivariate likelihood model (MVN), and Random  Forests.  When classification was done on 60s segments, a  maximum classification accuracy of 99. 0% was attained  in a cross-validation experiment.  In a more difficult  unseen generalization experiment, accuracy was 75%.    III.  TECHNICAL WORK PREPARATION  A. Problem Statement  The objective of the paper is to develop a system  which automatically mines the raga of an Indian Classical  Music.  The fig 3.1 shows the configuration of the  proposed system.  As a first step Note transcription is  applied on a given audio file to generate the sequence of  notes used to play the song.  In the next step, the features  related to Arohana â€“ Avarohana are extracted.  These  features are given to ANN for training and testing the  system. Figure 3.1 System Structure  B. Note Transcription  In order to identify the raga of the songs, the sequence  of notes used to play the song must be known. The  process of identifying the sequence of notes i.e the swara- script is called as Note Transcription.   For Indian  classical music, Note Transcription process itself is a  very challenging task.  Gaurav Pandey used two  heuristics, based on the pitch of the audio sample for  Note transcription, The Hill Peak Heuristic and Note  Duration Heuristic, [5]. 

