Fig. 1. Workﬂow execution steps.set of control ﬂow constructs, including iterative and parallelconstructs.
 A lack of ﬂexibility to adapt to unexpected events can be a signiﬁcant downfall2168-7161 (c) 2013 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission.  See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.  This article has been accepted for publication in a future issue of this journal, but has not been fully edited.  Content may change prior to final publication.  Citation information: DOI 10. 1109/TCC.2014.2378790, IEEE Transactions on Cloud Computing 3 and is in fact considered to be a major weakness of scheduled solution.  A workﬂow will be pre-partitioned based on its structure.  Our workﬂow management system (WfMS) is brieﬂy de- scribed as follows, as illustrated in Fig. 1. First, Users compose workﬂows using an XML generator to produce an XML based workﬂow description that shields users from the system details.  WfMS takes this abstract description and information about the available resources and generates an executable workﬂow that describes the computation, data transfers and data registration tasks and their dependencies.  The WfMS scheduler consults various sites information services, such as the Globus Monitoring and Discovery Service (MDS), the Globus Replica Location Service (RLS), Transformation Catalog (TC), and the Metadata Catalog Service (MCS), to determine the available computational resources and data.  Given all the information, the scheduler can select resources to execute tasks based on the available resources and their characteristics as well as the location of the required data.  Users can select the following algorithms to schedule their workﬂows: HEFT [23], random, round-robin, min-min [13], game-quick [9], etc.  With a scheduled workﬂow, we can post- partition it and optimize its data ﬂow, and these mechanics are presented in the sequel.  WfMS generates an executable workﬂow, which identiﬁes the resources where the computa- tion will take place, identiﬁes the data movement for staging data in and out of the computation and intermediate data, and registers the newly derived data products in the RLS and MCS. As depicted in Fig. 1, a workﬂow can be regularly evaluated and adjusted at run time. 

