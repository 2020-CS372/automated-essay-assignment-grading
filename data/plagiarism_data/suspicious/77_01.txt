Figure 2: Viterbi Decoder for the convolutional coding
 It was originally invented to decode  convolutional codes[2].  So, the introduction of the  Viterbi algorithm will mainly be based on the  decoding process for the convolution coding.   There exist several statistical tools in VA  estimation such as the Maximum A posteriori  Probability (MAP)[3] and Maximum Likelihood  Sequence Estimation (MLSE) [1, 4-7].    1.2  MAP and MLSE  MAP and MLSE can be both viewed as a  derivation from the BAYES Estimation[8, 9].    In  BAYES criterion, two notations are made:   • the priori probabilities (denoted as P (H 0 ) and P  (H 1 ))   • The cost to each possible decision (denoted as C ij ),  i, j = 0, 1, as the cost associated with the decision  D i  given that the true hypothesis is H j .  Hence, the  decision rule resulting from the BAYES criterion  is:  ) ( ) ( ) / ( ) / ( 11 01 1 00 10 0 0 / 1 1 / 0 1 0 C C P C C P H Y f H Y f H H H Y H Y − − < >   In MAP , let the costs   Cii = 0, i = 0, 1  Cij = 1, i ≠ j and i, j = 0, 1  Hence, minimizing the risk is equivalent to  minimizing the probability of error.  Then, the decision  rule is reduced to     ) / ( ) / ( 0 1 0 1 y H P y H P H H < >   In MLSE, let  ) ( ) ( 11 01 1 00 10 0 C C P C C P − = −  It yields:  ) / ( ) / ( 2 1 0 1 H y p H y P H H < >   1. 3  Viterbi Decoder  The convolution encoder is basically a finite-state  machine, and the VA decoding is done on the optimal  decoder based on MLSE[4].Figure 2 shows the block  diagram in which the convolutional coding and Viterbi  decoding are applied. 00 (c) IEEE     Figure 2: Viterbi Decoder for the convolutional  coding  The Viterbi decoding involves the search through  the trellis for the most likely sequence. i.e., to select  the path with the maximum probability of P (z|x),  where z is the received sequence and x is the signal  which is needed to estimate.  If the error probability in  channel is P (1|0) =P (0|1) = p, L is the sequence  length, and e is the number of error bits at the same  time e L e p p x z P − − = ) 1 ( ) ( Be A p p e p L x z P − − = − − − = ) 1 log( ) 1 log( ) ( log  , where p L A − = 1 1 log , ) 1 log( p p B − =    They are both positive constants 1 .      It means that finding the maximum likelihood path  in trellis diagram is equivalent to finding the minimum  hamming distance.    Figure3 (series) shows the bit sequences in the  convolutional coding and decoding process.  Figure  3-1 is the original signal with length of 20.  Figure 3-2  is the sequence after the (2, 1, 3) convolutional coding. 

